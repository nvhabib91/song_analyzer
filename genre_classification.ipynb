{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Paths\n",
    "training_data = pd.read_csv(\"analysis_data_sources\\CAL10K_with_Spotify_WithFeatures.tab\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24731, 14) (24731,)\n"
     ]
    }
   ],
   "source": [
    "X = training_data.drop(columns=['Spotify_ID', 'Song', 'Genre'], axis=1)\n",
    "y = training_data[\"Genre\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.249</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-13.619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.193</td>\n",
       "      <td>110.636</td>\n",
       "      <td>256240.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0           0         0.498   0.249  9.0   -13.619   0.0       0.0355   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0         0.755          0.000009    0.0927    0.193  110.636     256240.0   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=100, activation='relu', input_dim=14))\n",
    "deep_model.add(Dense(units=100, activation='relu'))\n",
    "deep_model.add(Dense(units=147, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "deep_model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "580/580 - 1s - loss: 0.5017 - accuracy: 0.8239\n",
      "Epoch 2/120\n",
      "580/580 - 1s - loss: 0.5076 - accuracy: 0.8205\n",
      "Epoch 3/120\n",
      "580/580 - 1s - loss: 0.5017 - accuracy: 0.8220\n",
      "Epoch 4/120\n",
      "580/580 - 1s - loss: 0.4944 - accuracy: 0.8273\n",
      "Epoch 5/120\n",
      "580/580 - 1s - loss: 0.4967 - accuracy: 0.8235\n",
      "Epoch 6/120\n",
      "580/580 - 1s - loss: 0.5007 - accuracy: 0.8222\n",
      "Epoch 7/120\n",
      "580/580 - 1s - loss: 0.4978 - accuracy: 0.8239\n",
      "Epoch 8/120\n",
      "580/580 - 1s - loss: 0.5008 - accuracy: 0.8261\n",
      "Epoch 9/120\n",
      "580/580 - 1s - loss: 0.4925 - accuracy: 0.8280\n",
      "Epoch 10/120\n",
      "580/580 - 1s - loss: 0.4951 - accuracy: 0.8274\n",
      "Epoch 11/120\n",
      "580/580 - 1s - loss: 0.4902 - accuracy: 0.8268\n",
      "Epoch 12/120\n",
      "580/580 - 1s - loss: 0.4873 - accuracy: 0.8288\n",
      "Epoch 13/120\n",
      "580/580 - 1s - loss: 0.4863 - accuracy: 0.8295\n",
      "Epoch 14/120\n",
      "580/580 - 1s - loss: 0.4919 - accuracy: 0.8276\n",
      "Epoch 15/120\n",
      "580/580 - 1s - loss: 0.4793 - accuracy: 0.8313\n",
      "Epoch 16/120\n",
      "580/580 - 1s - loss: 0.4895 - accuracy: 0.8295\n",
      "Epoch 17/120\n",
      "580/580 - 1s - loss: 0.4807 - accuracy: 0.8316\n",
      "Epoch 18/120\n",
      "580/580 - 1s - loss: 0.4845 - accuracy: 0.8303\n",
      "Epoch 19/120\n",
      "580/580 - 1s - loss: 0.4864 - accuracy: 0.8281\n",
      "Epoch 20/120\n",
      "580/580 - 1s - loss: 0.4861 - accuracy: 0.8290\n",
      "Epoch 21/120\n",
      "580/580 - 1s - loss: 0.4901 - accuracy: 0.8275\n",
      "Epoch 22/120\n",
      "580/580 - 1s - loss: 0.4881 - accuracy: 0.8302\n",
      "Epoch 23/120\n",
      "580/580 - 1s - loss: 0.4826 - accuracy: 0.8293\n",
      "Epoch 24/120\n",
      "580/580 - 1s - loss: 0.4735 - accuracy: 0.8319\n",
      "Epoch 25/120\n",
      "580/580 - 1s - loss: 0.4803 - accuracy: 0.8304\n",
      "Epoch 26/120\n",
      "580/580 - 1s - loss: 0.4755 - accuracy: 0.8329\n",
      "Epoch 27/120\n",
      "580/580 - 1s - loss: 0.4748 - accuracy: 0.8332\n",
      "Epoch 28/120\n",
      "580/580 - 1s - loss: 0.4720 - accuracy: 0.8353\n",
      "Epoch 29/120\n",
      "580/580 - 1s - loss: 0.4711 - accuracy: 0.8349\n",
      "Epoch 30/120\n",
      "580/580 - 1s - loss: 0.4709 - accuracy: 0.8324\n",
      "Epoch 31/120\n",
      "580/580 - 1s - loss: 0.4639 - accuracy: 0.8404\n",
      "Epoch 32/120\n",
      "580/580 - 1s - loss: 0.4640 - accuracy: 0.8365\n",
      "Epoch 33/120\n",
      "580/580 - 1s - loss: 0.4675 - accuracy: 0.8358\n",
      "Epoch 34/120\n",
      "580/580 - 1s - loss: 0.4639 - accuracy: 0.8354\n",
      "Epoch 35/120\n",
      "580/580 - 1s - loss: 0.4657 - accuracy: 0.8335\n",
      "Epoch 36/120\n",
      "580/580 - 1s - loss: 0.4715 - accuracy: 0.8318\n",
      "Epoch 37/120\n",
      "580/580 - 1s - loss: 0.4622 - accuracy: 0.8364\n",
      "Epoch 38/120\n",
      "580/580 - 1s - loss: 0.4627 - accuracy: 0.8351\n",
      "Epoch 39/120\n",
      "580/580 - 1s - loss: 0.4616 - accuracy: 0.8375\n",
      "Epoch 40/120\n",
      "580/580 - 1s - loss: 0.4693 - accuracy: 0.8322\n",
      "Epoch 41/120\n",
      "580/580 - 1s - loss: 0.4555 - accuracy: 0.8390\n",
      "Epoch 42/120\n",
      "580/580 - 1s - loss: 0.4583 - accuracy: 0.8395\n",
      "Epoch 43/120\n",
      "580/580 - 1s - loss: 0.4617 - accuracy: 0.8348\n",
      "Epoch 44/120\n",
      "580/580 - 1s - loss: 0.4590 - accuracy: 0.8383\n",
      "Epoch 45/120\n",
      "580/580 - 1s - loss: 0.4519 - accuracy: 0.8417\n",
      "Epoch 46/120\n",
      "580/580 - 1s - loss: 0.4561 - accuracy: 0.8396\n",
      "Epoch 47/120\n",
      "580/580 - 1s - loss: 0.4599 - accuracy: 0.8387\n",
      "Epoch 48/120\n",
      "580/580 - 1s - loss: 0.4620 - accuracy: 0.8378\n",
      "Epoch 49/120\n",
      "580/580 - 1s - loss: 0.4522 - accuracy: 0.8425\n",
      "Epoch 50/120\n",
      "580/580 - 1s - loss: 0.4503 - accuracy: 0.8417\n",
      "Epoch 51/120\n",
      "580/580 - 1s - loss: 0.4567 - accuracy: 0.8383\n",
      "Epoch 52/120\n",
      "580/580 - 1s - loss: 0.4546 - accuracy: 0.8391\n",
      "Epoch 53/120\n",
      "580/580 - 1s - loss: 0.4480 - accuracy: 0.8411\n",
      "Epoch 54/120\n",
      "580/580 - 1s - loss: 0.4547 - accuracy: 0.8397\n",
      "Epoch 55/120\n",
      "580/580 - 1s - loss: 0.4463 - accuracy: 0.8432\n",
      "Epoch 56/120\n",
      "580/580 - 1s - loss: 0.4481 - accuracy: 0.8421\n",
      "Epoch 57/120\n",
      "580/580 - 1s - loss: 0.4399 - accuracy: 0.8449\n",
      "Epoch 58/120\n",
      "580/580 - 1s - loss: 0.4554 - accuracy: 0.8410\n",
      "Epoch 59/120\n",
      "580/580 - 1s - loss: 0.4420 - accuracy: 0.8429\n",
      "Epoch 60/120\n",
      "580/580 - 1s - loss: 0.4491 - accuracy: 0.8361\n",
      "Epoch 61/120\n",
      "580/580 - 1s - loss: 0.4339 - accuracy: 0.8484\n",
      "Epoch 62/120\n",
      "580/580 - 1s - loss: 0.4425 - accuracy: 0.8435\n",
      "Epoch 63/120\n",
      "580/580 - 1s - loss: 0.4412 - accuracy: 0.8429\n",
      "Epoch 64/120\n",
      "580/580 - 1s - loss: 0.4356 - accuracy: 0.8481\n",
      "Epoch 65/120\n",
      "580/580 - 1s - loss: 0.4440 - accuracy: 0.8437\n",
      "Epoch 66/120\n",
      "580/580 - 1s - loss: 0.4373 - accuracy: 0.8464\n",
      "Epoch 67/120\n",
      "580/580 - 1s - loss: 0.4362 - accuracy: 0.8466\n",
      "Epoch 68/120\n",
      "580/580 - 1s - loss: 0.4368 - accuracy: 0.8462\n",
      "Epoch 69/120\n",
      "580/580 - 1s - loss: 0.4364 - accuracy: 0.8421\n",
      "Epoch 70/120\n",
      "580/580 - 1s - loss: 0.4291 - accuracy: 0.8461\n",
      "Epoch 71/120\n",
      "580/580 - 1s - loss: 0.4399 - accuracy: 0.8458\n",
      "Epoch 72/120\n",
      "580/580 - 1s - loss: 0.4363 - accuracy: 0.8440\n",
      "Epoch 73/120\n",
      "580/580 - 1s - loss: 0.4327 - accuracy: 0.8463\n",
      "Epoch 74/120\n",
      "580/580 - 1s - loss: 0.4275 - accuracy: 0.8481\n",
      "Epoch 75/120\n",
      "580/580 - 1s - loss: 0.4413 - accuracy: 0.8427\n",
      "Epoch 76/120\n",
      "580/580 - 1s - loss: 0.4199 - accuracy: 0.8527\n",
      "Epoch 77/120\n",
      "580/580 - 1s - loss: 0.4231 - accuracy: 0.8489\n",
      "Epoch 78/120\n",
      "580/580 - 1s - loss: 0.4326 - accuracy: 0.8445\n",
      "Epoch 79/120\n",
      "580/580 - 1s - loss: 0.4238 - accuracy: 0.8501\n",
      "Epoch 80/120\n",
      "580/580 - 1s - loss: 0.4254 - accuracy: 0.8466\n",
      "Epoch 81/120\n",
      "580/580 - 1s - loss: 0.4330 - accuracy: 0.8454\n",
      "Epoch 82/120\n",
      "580/580 - 1s - loss: 0.4305 - accuracy: 0.8459\n",
      "Epoch 83/120\n",
      "580/580 - 1s - loss: 0.4170 - accuracy: 0.8544\n",
      "Epoch 84/120\n",
      "580/580 - 1s - loss: 0.4270 - accuracy: 0.8493\n",
      "Epoch 85/120\n",
      "580/580 - 1s - loss: 0.4256 - accuracy: 0.8487\n",
      "Epoch 86/120\n",
      "580/580 - 1s - loss: 0.4253 - accuracy: 0.8503\n",
      "Epoch 87/120\n",
      "580/580 - 1s - loss: 0.4142 - accuracy: 0.8504\n",
      "Epoch 88/120\n",
      "580/580 - 1s - loss: 0.4211 - accuracy: 0.8527\n",
      "Epoch 89/120\n",
      "580/580 - 1s - loss: 0.4210 - accuracy: 0.8513\n",
      "Epoch 90/120\n",
      "580/580 - 1s - loss: 0.4119 - accuracy: 0.8539\n",
      "Epoch 91/120\n",
      "580/580 - 1s - loss: 0.4244 - accuracy: 0.8448\n",
      "Epoch 92/120\n",
      "580/580 - 1s - loss: 0.4160 - accuracy: 0.8505\n",
      "Epoch 93/120\n",
      "580/580 - 1s - loss: 0.4227 - accuracy: 0.8494\n",
      "Epoch 94/120\n",
      "580/580 - 1s - loss: 0.4119 - accuracy: 0.8523\n",
      "Epoch 95/120\n",
      "580/580 - 1s - loss: 0.4270 - accuracy: 0.8485\n",
      "Epoch 96/120\n",
      "580/580 - 1s - loss: 0.4185 - accuracy: 0.8498\n",
      "Epoch 97/120\n",
      "580/580 - 1s - loss: 0.4153 - accuracy: 0.8521\n",
      "Epoch 98/120\n",
      "580/580 - 1s - loss: 0.4105 - accuracy: 0.8525\n",
      "Epoch 99/120\n",
      "580/580 - 1s - loss: 0.4195 - accuracy: 0.8482\n",
      "Epoch 100/120\n",
      "580/580 - 1s - loss: 0.4073 - accuracy: 0.8543\n",
      "Epoch 101/120\n",
      "580/580 - 1s - loss: 0.4115 - accuracy: 0.8531\n",
      "Epoch 102/120\n",
      "580/580 - 1s - loss: 0.4054 - accuracy: 0.8575\n",
      "Epoch 103/120\n",
      "580/580 - 1s - loss: 0.4259 - accuracy: 0.8507\n",
      "Epoch 104/120\n",
      "580/580 - 1s - loss: 0.4063 - accuracy: 0.8539\n",
      "Epoch 105/120\n",
      "580/580 - 1s - loss: 0.4152 - accuracy: 0.8522\n",
      "Epoch 106/120\n",
      "580/580 - 1s - loss: 0.4078 - accuracy: 0.8531\n",
      "Epoch 107/120\n",
      "580/580 - 1s - loss: 0.4030 - accuracy: 0.8577\n",
      "Epoch 108/120\n",
      "580/580 - 1s - loss: 0.4055 - accuracy: 0.8601\n",
      "Epoch 109/120\n",
      "580/580 - 1s - loss: 0.4057 - accuracy: 0.8552\n",
      "Epoch 110/120\n",
      "580/580 - 1s - loss: 0.4126 - accuracy: 0.8527\n",
      "Epoch 111/120\n",
      "580/580 - 1s - loss: 0.4027 - accuracy: 0.8568\n",
      "Epoch 112/120\n",
      "580/580 - 1s - loss: 0.4122 - accuracy: 0.8533\n",
      "Epoch 113/120\n",
      "580/580 - 1s - loss: 0.4175 - accuracy: 0.8511\n",
      "Epoch 114/120\n",
      "580/580 - 1s - loss: 0.3882 - accuracy: 0.8651\n",
      "Epoch 115/120\n",
      "580/580 - 1s - loss: 0.3977 - accuracy: 0.8573\n",
      "Epoch 116/120\n",
      "580/580 - 1s - loss: 0.4122 - accuracy: 0.8551\n",
      "Epoch 117/120\n",
      "580/580 - 1s - loss: 0.4123 - accuracy: 0.8511\n",
      "Epoch 118/120\n",
      "580/580 - 1s - loss: 0.3978 - accuracy: 0.8582\n",
      "Epoch 119/120\n",
      "580/580 - 1s - loss: 0.3984 - accuracy: 0.8572\n",
      "Epoch 120/120\n",
      "580/580 - 1s - loss: 0.4027 - accuracy: 0.8562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db8d9c1608>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=120,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "deep_model.save('genre_trained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "deep_model = load_model(\"genre_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 - 0s - loss: 1.2132 - accuracy: 0.7469\n",
      "Normal Neural Network - Loss: 1.213161587715149, Accuracy: 0.7468866109848022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = deep_model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_predictions = deep_model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['alternative', 'funk', 'country', 'soul', 'alternative']\n",
      "Actual Labels: ['alternative', 'hip hop', 'country', 'outside lands music festival radio', 'alternative country']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted: {list(prediction_labels)}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
