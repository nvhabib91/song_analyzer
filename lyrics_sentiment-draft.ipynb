{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Testing techniques between TextBlob and vaderSentiment\n",
    "##### Also using the lyricsgenius API vs AZ lyrics/other lyrics source (will validate for ease of use)\n",
    "##### Testing only one song corrently at a time\n",
    "##### Expected output: pos/neg/neutral for Vader, polarity/subjectivity for TextBlob\n",
    "\n",
    "#####\n",
    "\n",
    "###### Stretch goals: (secret po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies set up:\n",
    "\n",
    "# Dataframe building, analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scraping data/lyrics\n",
    "import lyricsgenius\n",
    "\n",
    "# Data Preprocessing\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob Section ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Adele...\n",
      "\n",
      "\"19 [Booklet]\" is not valid. Skipping.\n",
      "Song 1: \"2017 Grammyâ€™s Song of the Year Speech\"\n",
      "\n",
      "Reached user-specified song limit (1).\n",
      "Done. Found 1 songs.\n",
      "Searching for \"All I Ask\" by Adele...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[Verse 1]\\nI will leave my heart at the door\\nI won't say a word\\nThey've all been said before, you know\\nSo why don't we just play pretend\\nLike we're not scared of what is coming next\\nOr scared of having nothing left?\\n\\n[Pre-Chorus]\\nLook, don't get me wrong\\nI know there is no tomorrow\\nAll I ask is\\n\\n[Chorus]\\nIf this is my last night with you\\nHold me like I'm more than just a friend\\nGive me a memory I can use\\nTake me by the hand while we do\\nWhat lovers do\\nIt matters how this ends\\n'Cause what if I never love again?\\n\\n[Verse 2]\\nI don't need your honesty\\nIt's already in your eyes\\nAnd I'm sure my eyes, they speak for me\\nNo one knows me like you do\\nAnd since you're the only one that mattered\\nTell me, who do I run to?\\n\\n[Pre-Chorus]\\nLook, don't get me wrong\\nI know there is no tomorrow\\nAll I ask is\\n\\n[Chorus]\\nIf this is my last night with you\\nHold me like I'm more than just a friend\\nGive me a memory I can use\\nTake me by the hand while we do\\nWhat lovers do\\nIt matters how this ends\\n'Cause what if I never love again?\\n\\n[Bridge]\\nLet this be our lesson in love\\nLet this be the way we remember us\\nI don't want to be cruel or vicious\\nAnd I ain't asking for forgiveness\\nAll I ask is\\n\\n[Chorus]\\nIf this is my last night with you\\nHold me like I'm more than just a friend\\nGive me a memory I can use\\nTake me by the hand while we do\\nWhat lovers do\\nIt matters how this ends\\n'Cause what if I never love again?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lyricsgenius\n",
    "genius = lyricsgenius.Genius(\"9TKmoq_foRHodVBBuM-5doQJNej6I5gqgPk6Kkde_Qhxx3ZW6nOBZWGfHMnwCmuL\")\n",
    "artist = \"Adele\"\n",
    "search_artist = genius.search_artist(artist, max_songs=1, sort=\"title\")\n",
    "song = genius.search_song(\"All I Ask\", search_artist.name)\n",
    "lyrics = song.lyrics\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Test \n",
    "# lyrics_url = \"https://www.azlyrics.com/lyrics/pharrellwilliams/happy.html\"\n",
    "# response = requests.get(lyrics_url)\n",
    "# soup = BeautifulSoup(response.text, 'lxml')\n",
    "# lyrics = soup.find('div', class_=None).text\n",
    "# lyrics = lyrics.replace('\\n', ' ').replace('\\r', ' ')\n",
    "# lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Cleaning the lyrics of words that describe parts of the song, such as [Chorus:], [Explicit:], [Verse 2:] etc. \n",
    "lyrics = re.sub('\\\\[[^\\\\]]*\\\\]', '', lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Expand contractions\n",
    "exp_lyrics = contractions.fix(lyrics)\n",
    "exp_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Converted all the words into lowercase in case capitalization interferes with the weight of the words, removed leading and trailing spaces. Also removes instance of () where it occurs, but keeps the words.\n",
    "lyrics = exp_lyrics.lower().strip().replace('   ', ' ').replace('(', '').replace(')', '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Remove punctuations\n",
    "punc_lyrics = lyrics.translate(str.maketrans('','', string.punctuation))\n",
    "punc_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3. Tokenizing? \n",
    "tokenized_lyrics = nltk.word_tokenize(punc_lyrics)\n",
    "tokenized_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4. Remove stopwords?\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_lyrics = [lyrics for lyrics in tokenized_lyrics if not lyrics in stop_words]\n",
    "filtered_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Convert list to string. Lemmatize?\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "lemmatized = ' '.join([lemm.lemmatize(words) for words in filtered_lyrics])\n",
    "\n",
    "# [lemmatizer.lemmatize(w) for w in word_list]\n",
    "\n",
    "# lemmatized = lemm.lemmatize(filtered_string)\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TextBlob Sentiment?\n",
    "from textblob import TextBlob\n",
    "text_sentiment = TextBlob(lemmatized).sentiment\n",
    "text_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VaderSentiment Section ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_v = analyzer.polarity_scores(punc_lyrics)\n",
    "polarity_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function with TextBlob\n",
    "\n",
    "def text_blob_sentiment(lyrics):\n",
    "    lyrics = re.sub('\\\\[[^\\\\]]*\\\\]', '', lyrics)\n",
    "    lyrics_cont = contractions.fix(lyrics)\n",
    "    char_lyrics = lyrics_cont.lower().strip().replace('(', '').replace(')', '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    punc_lyrics = char_lyrics.translate(str.maketrans('','', string.punctuation))\n",
    "    \n",
    "    #Tokenize\n",
    "    tokenized_lyrics = nltk.word_tokenize(punc_lyrics)\n",
    "    \n",
    "    #Stop words have to be stored and loaded first\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_lyrics = [lyrics for lyrics in tokenized_lyrics if not lyrics in stop_words]\n",
    "    \n",
    "    #Join for lemmatization\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    lemmatized = ' '.join([lemm.lemmatize(words) for words in stop_lyrics])\n",
    "    text_sentiment = TextBlob(lemmatized).sentiment\n",
    "    \n",
    "    print(text_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.19642857142857142, subjectivity=0.5206349206349206)\n"
     ]
    }
   ],
   "source": [
    "text_blob_sentiment(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function with VaderSentiment\n",
    "\n",
    "def vader_sentiment(lyrics):\n",
    "    lyrics = re.sub('\\\\[[^\\\\]]*\\\\]', '', lyrics)\n",
    "    lyrics_cont = contractions.fix(lyrics)\n",
    "    char_lyrics = lyrics_cont.lower().strip().replace('(', '').replace(')', '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    punc_lyrics = char_lyrics.translate(str.maketrans('','', string.punctuation))\n",
    "    \n",
    "    #Tokenize\n",
    "    tokenized_lyrics = nltk.word_tokenize(punc_lyrics)\n",
    "    \n",
    "    #Stop words have to be stored and loaded first\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_lyrics = [lyrics for lyrics in tokenized_lyrics if not lyrics in stop_words]\n",
    "    \n",
    "    #Join for lemmatization\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    lemmatized = ' '.join([lemm.lemmatize(words) for words in stop_lyrics])\n",
    "    \n",
    "    #Sentiment Analysis\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    text_sentiment = analyzer.polarity_scores(lemmatized)\n",
    "    \n",
    "    print(text_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.211, 'neu': 0.421, 'pos': 0.368, 'compound': 0.9685}\n"
     ]
    }
   ],
   "source": [
    "vader_sentiment(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
